{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9bb11b3",
   "metadata": {},
   "source": [
    "# process_dictionary\n",
    "\n",
    "Process a dictionary file in json format and extract all words between `min_word_length` and `max_word_length`. \n",
    "\n",
    "This produces a json file that contains the following:\n",
    "\n",
    "* dictonary of all matching words with\n",
    "    - score for 1, 2, 3 letter frequency matches \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "93810fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = './valid-wordle-words.txt'\n",
    "min_word_length = 5\n",
    "max_word_length = 5\n",
    "max_letter_combinations = 3\n",
    "rounding_places = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e6ce09e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "from operator import getitem\n",
    "from itertools import product \n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8d0e133f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# local\n",
    "from pathlib import Path\n",
    "word_file = Path(word_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fee6131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def range_char(start, stop):\n",
    "    '''generator for all characters in range `start:stop`\n",
    "    \n",
    "    works effectively for upper:upper or lower:lower case letters'''\n",
    "    return (chr(n) for n in range(ord(start), ord(stop) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "be6cbe63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_dict(d, n):\n",
    "    r = {}\n",
    "    for i in random.sample(sorted(d), n):\n",
    "        r[i] = d[i]\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "da0c04f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_dict(d, h):\n",
    "    fd = []\n",
    "\n",
    "    for key, values in d.items():\n",
    "        entry = {}\n",
    "        entry[h] = key\n",
    "        entry.update(values)\n",
    "        fd.append(entry)\n",
    "        \n",
    "    return fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e83f8ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = {}\n",
    "with open(word_file, 'r') as f:\n",
    "    for line in f:\n",
    "        all_words[line.strip()] = len(line.strip())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f0dcd2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort dictionary by word length\n",
    "new_d = {}\n",
    "for k in sorted(all_words_dict, key=len, reverse=False):\n",
    "    new_d[k] = all_words_dict[k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4d500590",
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_words = {}\n",
    "for k in new_d:\n",
    "    # pull words of matching length\n",
    "    if len(k) >= min_word_length and len(k) <= max_word_length:\n",
    "        accepted_words[k] = {}\n",
    "        \n",
    "    # stop after first word that is too long\n",
    "    if len(k) > max_word_length:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73c9d0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary of letter combination dictionaries with all cartesian product of characters a..z:\n",
    "c_product_dicts = {}\n",
    "for length in range(1, max_letter_combinations+1):\n",
    "    # create a dictionary for each length\n",
    "    c_product_dicts[length] = {}\n",
    "#     for i in permutations(''.join(range_char('a', 'z')), length):\n",
    "    for i in product(range_char('a', 'z'), repeat = length):\n",
    "        c_product_dicts[length][''.join(i)] = {'total': 0, 'percent': 0, 'score': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dbed1968",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for word in accepted_words:\n",
    "    for i, letter in enumerate(word):\n",
    "        for j in range(1, max_letter_combinations+1):\n",
    "            if i+j > len(word):\n",
    "                pass\n",
    "            else:\n",
    "                w_slice=(f'{word[i:i+j]}')\n",
    "                c_product_dicts[j][w_slice]['total'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d037fa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_bins = {}\n",
    "for dictionary, letter_space in c_product_dicts.items():\n",
    "    # create bins for values\n",
    "    dictionary_bins[dictionary] = {'total': 0, 'bins': []}\n",
    "    # sum up the total occurences of each value in the letter space\n",
    "    for key, value in letter_space.items():\n",
    "        dictionary_bins[dictionary]['total'] += value['total']\n",
    "    # assign a percent score for each value\n",
    "    value_list = []\n",
    "    for key, value in letter_space.items():\n",
    "        value['percent'] = round(value['total']/dictionary_bins[dictionary]['total'], rounding_places)\n",
    "        value_list.append(value['percent'])\n",
    "    # re-order the space by highest percent value first\n",
    "    c_product_dicts[dictionary] = OrderedDict(\n",
    "        sorted(letter_space.items(), key=lambda x: getitem(x[1], 'percent'), reverse=True))\n",
    "    dictionary_bins[dictionary]['bins'] = sorted(set(value_list), reverse=True)\n",
    "    \n",
    "    # score each value in letter_space using bin index (lower scores are better)\n",
    "    for key, value in letter_space.items():\n",
    "        value['score'] = dictionary_bins[dictionary]['bins'].index(value['percent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "16f7fd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider stripping out all values in letter space with score of 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ba02355d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull N random words from dictionary\n",
    "\n",
    "# test_words = sample_dict(accepted_words, 10)\n",
    "# test_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "bc114f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is expensive to run!\n",
    "# calculate the score of each word for each value in the letter spaces\n",
    "for word, data in accepted_words.items():\n",
    "    for dictionary, letter_space in c_product_dicts.items():\n",
    "        score = 0\n",
    "        for item in letter_space:\n",
    "            count = word.count(item)\n",
    "            score += letter_space[item]['score'] * count           \n",
    "        data[dictionary] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "3a806d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create CSV friendly rendering of frequency data\n",
    "freqeuncy_csv = []\n",
    "for d, values in c_product_dicts.items():\n",
    "    freqeuncy_csv.extend(flatten_dict(values, 'letter'))\n",
    "accepted_words_csv = flatten_dict(accepted_words, 'word')\n",
    "\n",
    "# remove all words with duplicate characters\n",
    "accepted_words_no_dupes_csv = []\n",
    "for word in accepted_words_csv:\n",
    "    if len(set(word['word'])) == len(word['word']):\n",
    "        accepted_words_no_dupes_csv.append(word)\n",
    "        \n",
    "\n",
    "# sort based lowest score for first three keys\n",
    "accepted_words_sorted_csv = sorted(accepted_words_csv, key=lambda d: (d[1], d[2], d[3]))\n",
    "accepted_words_no_dupes_sorted_csv = sorted(accepted_words_no_dupes_csv, key=lambda d: (d[1], d[2], d[3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "4816e15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = [\n",
    "    {'file_name': 'frequency.csv', 'var': freqeuncy_csv, 'fieldnames': freqeuncy_csv[0].keys()},\n",
    "    {'file_name': 'accepted_words.csv', 'var': accepted_words_csv, 'fieldnames': accepted_words_csv[0].keys()},\n",
    "    {'file_name': 'accepted_words_sorted.csv', 'var': accepted_words_sorted_csv, 'fieldnames': accepted_words_sorted_csv[0].keys()},\n",
    "    {'file_name': 'accepted_words_no_dupes_sorted.csv', 'var': accepted_words_no_dupes_csv, 'fieldnames': accepted_words_no_dupes_csv[0].keys()}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "4efcfc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in csv_files:\n",
    "    with open(file['file_name'], 'w') as csv_file:\n",
    "        writer = csv.DictWriter(csv_file, delimiter=',', fieldnames=file['fieldnames'])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(file['var'])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wordle-fe1iP-uY",
   "language": "python",
   "name": "wordle-fe1ip-uy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
